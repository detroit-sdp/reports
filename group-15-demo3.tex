%% Template for SDP report, adapted from mlp_cw2_template, 2018. 

%% Based on  LaTeX template for ICML 2017 - example_paper.tex at 
%%  https://2017.icml.cc/Conferences/2017/StyleAuthorInstructions

\documentclass{article}
\input{mlp2018_includes}

%% You probably do not need to change anything above this comment

%% REPLACE the details in the following commands with your details
\setGroupNumber{15}
\setGroupName{Detroit}
\setProductName{Tadashi}
\setDemoNumber{3}
\setLogoFileName{figs/logo-small.png}

\begin{document} 

\makeSDPTitle{Demo}

% Previous MLP Style Title Layout working. 
% \twocolumn[
    % \mlptitle{\productName: SDP Demo \demoNumber}
    % \centerline{Group \groupNumber: \groupName}
% ]

\begin{abstract}
  Tadashi is an assistive robot for delivering food and water to residents in supported living, care home, and quarantine environments.
  In this demo, we demonstrate significant progress towards a minimum viable product (MVP). We integrate components of our system together, demonstrating significant progress towards a full use case: the caregiver placing a delivery on the tray and scheduling the robot to visit a room; the robot navigating to the room; the lift extending on arrival and detecting that the resident has picked up the delivery using integrated weight sensors; the lift retracting once the delivery has been made, and the robot sending a message to the app to indicate this; and the robot returning to its starting point. We also discuss usability testing we have performed on our app to ensure it is usable by non-technical caregivers, and discuss future improvements to the app based on this. 
\end{abstract} 

\section{Project plan update} 
\begin{itemize}
\item Begin testing app with non-technical users to gain insights on accessibility and ease of use: {\bf achieved}.
\item Make changes to app justified against results of testing: {\bf partially achieved}.
\item Complete user interviews with caregivers to assess demand for project features and implement new features based on caregiver requests: {\bf not achieved}.
\item Physically integrate lift mechanism into robot body, and integrate lift control into robot control software: {\bf partially achieved}.
\item Design and manufacture a tray to place on top of the lift to hold items: {\bf achieved}.
\item Add sensor to lift to determine whether items have been removed: {\bf partially achieved}.
\item Refine robot problem-solving when stuck by tuning mapping sensitivity and obstacle avoidance logic: {\bf partially achieved}. 
\item Implement bi-directional communication between the app and robot: {\bf achieved}.
\end{itemize}

We were not able to complete user interviews due to delays in receiving ethical approval. We intend to complete these as soon as we receive the approval. 

\begin{table}[]
  \begin{tabular}{l|l}
    Task & Members \\
    \hline
    Robot refinements & Ben, Wojtek \\
    App refinements & Ching Ling, Yuchen \\
    Project management & Michael \\
    User testing & Theo \\
    Product development & Rebecca \\
    Lift building and mounting & Luukas \\
    Lift-robot connection & Errikos, Luukas, Jakub \\
    App-robot connection & Ben, Yuchen \\
  \end{tabular}
  \caption{Task splits across the group up to demo \demoNumber. Core teams and points of contact remain the same as with demo 2, but tasks were done by combining expertise across teams. }
  \label{tab:group-split}
\end{table}

We began the sprint with teams working as for demo 2 to refine individual components, then created ad-hoc teams to connect systems (\ref{tab:group-split}). We used pair programming to utilize each person's knowledge and reduce the need to merge code. We used GitHub for version control, and Slack and once-weekly meetings for communication.

Our total budget spending so far is shown in section \ref{budget}.

Owing to the ongoing coronavirus situation, the entire team began working remotely from Saturday 14th March. This means we needed to halt work on the robot and the lift, as we cannot access or run these remotely, meaning that goals relating to these parts of the system could only be partially completed. Decisions are still ongoing as to how to continue work in this situation, so our goals may change as the situation develops. Our original goals for demo 4 are given in the appendix, section \ref{goals}. Given the changing situation, we instead aim to do the following for demo 4:
\begin{itemize}
  \item Complete user interviews, analyze results, and implement changes to our product to match user demand.
  \item Improve app based on usability testing, and perform another round of usability tests to assess if changes have made a difference to usability. 
  \item Write the user guide. 
  \item Explore other technical additions to the product to ensure our technical time is spent in a way that adds value to the product. 
\end{itemize}

\section{Technical details}
\subsection{Connectivity}
To aid the reader with understanding how the system fits together, we provide two diagrams. Figure \ref{fig:seq} is a sequence diagram showing how each part of the system is involved in the use case mentioned in the abstract. Figure \ref{fig:connect-larger} shows the connections we have set up between each of the parts. 

\begin{figure}
  \begin{center}
    \includegraphics[width=\columnwidth]{figs/sequence.png}
  \end{center}
  \caption{A simplified view of the steps of our use case and how each part of the product is involved in the use case. Note that for simplicity, `Tadashi' represents both the Turtlebot and the ROS master.}
  \label{fig:seq}
\end{figure}

\subsubsection{App $\leftrightarrow$ robot}
In the previous demo we only demonstrated app $\rightarrow$ robot communication. Implementing the other direction was difficult because the app runs on an emulator. By introducing port forwarding we have been able to demonstrate app $\leftrightarrow$ robot communication. The host machine running the emulator receives the packets on a port and forwards them to another port on itself. This second port is setup through the emulation software to forward all traffic onto a port on the emulated device.

To facilitate the app $\leftrightarrow$ robot connection, the app now has a network service running in the background until the app closes. We want to have the service run at all times, but Android power saving optimizations will eventually destroy the service. The service may have to be moved to the foreground to avoid this. 

To communicate the state of the robot to the app, the robot stores the following information internally. Firstly, {\bf low battery}, which is set if the battery level gets below 15\%. This state requires the caregiver to charge the robot. {\bf Assistance required} is set if the robot cannot find a path to the goal. This state requires rescue from the caregiver. The other possible states are {\bf at base and not busy}, {\bf moving}, and {\bf arrived at goal}. The robot sends a packet to the app whenever its internal state changes, containing one of the statuses listed above. 

\subsubsection{Robot $\leftrightarrow$ lift}
The Turtlebot can send a command to extend or retract the lift to the Arduino controlling the lift. In return, the lift sends three bytes to the Turtlebot. The first two bytes are the voltage across the weight sensors, divided by 4 to fit 8 bits. The last byte is three zeroes followed by {\tt overloaded-retracted-retracting}\ {\tt -extended-extending}, representing the current state of the lift's movement.

To establish a connection between the Turtlebot and the Arduino controlling the lift, we reviewed multiple options (Bluetooth, WiFi). We decided that the fastest and most reliable method would be to use a serial connection between USB ports on each board.

The code to extend and retract the lift was already on the Arduino, so it was a case of writing a Python script that could read/write bytes of data over the cable. The Raspberry Pi sends a single byte to the Arduino with possible values from 0-2 indicating stop, extend lift, and retract lift respectively. The Arduino returns the status of the lift as well as the current readings from the two weight sensors.

The connection was initially unreliable due to synchronization issues. By sending 0-bytes to the Arduino we can determine if the connection is disconnected, or just delayed. Details of this are in the appendix, section \ref{connection}.

For safety reasons, if the connection between the Turtlebot and the Arduino is broken, the lift stops all operation. If the connection is not re-established within 20 seconds, the lift lowers itself down.  

\subsection{Hardware}
We attached the lift to the Turtlebot using MDF and mounting screws drilled into the Lego (figure \ref{fig:lift}). The lift is stable when the robot is moving. We also designed and manufactured a tray to place on top of the lift, indicating where items are to be placed (figure \ref{fig:sensor}). The figure also shows one of the weight sensors. We placed two weight sensors under the tray: these can be used to detect when deliveries have been placed and picked up on the robot. The weight sensors send voltage values to the Arduino, which are sent forward to the Turtlebot for interpretation. We intended to do testing to determine how best to interpret the weight sensor values but were not able to do this before the team moved to remote. 

To allow the Turtlebot to communicate with the lift, the EV3 brick was replaced with an Arduino (figure \ref{fig:arduino}), which contains scripts to move the lift up and down and communicate with the Turtlebot. 


\begin{figure}
  \begin{center}
    \includegraphics[width=0.7\columnwidth]{figs/lift_diag.png}
    \caption{Side view of the lift mounted to the Turtlebot. Points to note include the metal brackets used to fix the lift in place (1); the removal of the EV3 brick and addition of the Arduino kit and batteries (2); and the tray and weight sensor placed on top (3).}
  \label{fig:lift}
  \end{center}
\end{figure}

\subsection{User interface}
Using the app, the user will be able to add and remove room-resident pairs to the system. They will be able to send one-off deliveries as well as schedule a one-off or recurring delivery to a certain patient. Finally, the app will allow for the user to keep track of some robot diagnostics and general information like: delivery weight, time, location, and return weight (what was sent back); and the robots current status within the world as discussed below. Our 6 step user-testing exercise in Evaluation describes the expected operation of the app with respect to these tasks. We have finalized the four fragments that achieve this functionality using best practices for app design \cite{design, ux}:
\begin{enumerate}
  \item {\bf Dashboard}: for viewing robot/delivery information.
  \item {\bf Map}: shows top-down map of the ward with an icon on each room to add/remove. 
  \item {\bf Calendar}: for scheduling and checking robots itinerary.
  \item {\bf Me}: shows logged-in account general information.
\end{enumerate}

The main focus for this demo was on the calendar fragment, and the networking service. The calendar allows the user to select any date, and for the given date it displays the robot's itinerary (past and future) for that date, in chronological order.

 The events are stored and kept track of in a database within our Firebase setup. The database layout is described in table~\ref{tab:delivery-history} and table~\ref{tab:residents}. Bold entries represent fields that are linked between the tables, and italic entries represent fields which are linked to Firebase's authentication feature for secure user data storage. The robot status is stored using Firebase's real-time database as it is a constantly updating piece of information. 

\subsection{Software}
While operating, the robot knows its own position with respect to its starting point and the state of the map, with its starting point being the origin on the map. We set the starting position to be the base as marked on the arena floor. 

The navigation stack operates using vectors. When calculating the path from one point to another, the goal must be given as a pair of distances on the $x$ and $y$ axes and a rotation. The natural drift and goal distance tolerance mean that the robot does not always arrive at its exact intended location. As a result, using fixed vectors cause the robots accuracy to significantly deteriorate over time. However, its positional awareness remains accurate. In order to correct this, we decided to store the rooms as coordinates rather than vectors and have the robot calculate a vector based on these coordinates. When the robot drifts, the vector changes thereby minimising the effects of drift.

The robot operates using robot-based axes. In order for our base return vector calculation to remain as simple as possible, we have restricted the robot to a four-directional goal system. This means that our vector calculation, at worst, simply involves switching and/or negation of our calculated $x$ and $y$, rather than rotating the 'view' of the map based on the robots new orientation w.r.t its initial orientation. Table~\ref{tab:quaternions} shows the quaternion move for each direction. Returning to the base involves performing the 'opposite' move i.e. face left at goal \= face right at base, face backwards at goal \= face backwards at base.

When receiving a GOTO command from the app, we receive the room number. We use a dictionary to associate a room number with a tuple (($x$,$y$), rotation) where rotation is one of (L,F,R,B).

Based on observation, we believe that using the coordinates-vector system is more accurate over time than using distances. We were not able to test this before the team moved to remote working. 

In mounting the lift onto the Turtlebot, we increased the length of its footprint from 28.1cm to 40.0cm. We were concerned that this would cause the Turtlebot to drive into obstacles. We altered the <box\_size> parameter within the <collision> tag in the description of itself the robot provides to the navigation stack to reflect the change in size. The effect of this is difficult to test as we have set the robot to be very conservative in avoiding obstacles. 

We fine-tuned a number of parameters for the robot, described in table~\ref{tab:params}. Initial testing of these new parameters suggested that they improved the robot's obstacle avoidance, at the cost of a higher risk of the robot thinking it has gotten stuck.

\subsection{Business development}
The target market for Tadashi is care homes and supported living environments. There are approximately 433,000 people occupying care homes in the UK, with 5500 providers \cite{carehomes}. Currently, robots are being designed to take care of the elderly, however in these situations there is very little human interaction between the resident and the caregiver \cite{robotcarers}. Our robot is to be used to aid caregivers, not to take over their jobs.

Another target market we have recently identified for Tadashi is in quarantine situations. Tadashi could be used to deliver food, water, and other supplies to quarantined people without the need for medical staff to expose themselves to possible infection. With over 100 million Europeans in quarantine due to the ongoing threat of the coronavirus pandemic \cite{quarantine}, and people over 70 in the UK likely to be asked to self-isolate \cite{isolate} in the near future, we see a strong demand for assistive robots like Tadashi. A hotel in China has recently introduced a robot that serves food to quarantined patients \cite{peanut}. Tadashi improves on this idea by having a lift, which allows quarantined people with mobility issues to reach their deliveries.

\section{Evaluation}
We were unable to perform software and hardware testing, but our planned tests are described in the appendix: \ref{testing}. 
We performed usability testing to ensure the app was usable by non-technical caregivers. We decided to perform our testing in an iterative manner, performing three cycles of testing with app modifications during each cycle. Following discussions with Chris during his office hour, a cycle consists of 5 steps.
Step 1, prepare a testing task for the user to complete.
Step 2, self-evaluate our app against the task to check for clear problems.
Step 3, minor modifications to the task or app based on self-evaluation.
Step 4, conduct user testing.
Step 5, major app modifications based on testing.

For demo \demoNumber\ we performed one cycle of testing:

{\bf Step 1}: We set 6 steps for the user to follow, each relevant to one of the 10 usability principles \cite{heuristics}:
\begin{enumerate}
  \item Create an account and sign in. \\{\it Standardization: since most users already have experience with sign-up screens, we used a default template.}
  \item Add 3 new residents to the rooms of the map. \\{\it Matching between the system and the real world: since the map represents a real care home floor, we want the user to intuitively recognize the layout, so the map is in the layout of the care home.}
  \item Send Tadashi to deliver to a resident. \\{\it User control: we want the user to feel in control of the robot, so we provide feedback and undo options.}
  \item Set a delivery for a later date in the calendar. \\{\it Standardization: the look of the scheduling system mimics Outlook, which users will be familiar with.}
  \item Report back information contained in the dashboard. \\{\it Visibility of system status: the dashboard is the most updated feature and contains key information, so it needs to display information relevant to the user in an intuitive manner.}
  \item Sign out. \\{\it Minimalism: we keep the settings area clear so users aren't confused on where to sign out.}
\end{enumerate}

{\bf Step 2}: During the self evaluation stage we completed a cognitive walkthrough of the app, putting us in the mind of a new user and completing our set tasks. The main problem found here was a general lack of direction and advice. Since the user starts at the dashboard, it wasn't immediately obvious that they should then use the map section to start adding residents.

{\bf Step 3}: Before proceeding with testing, we added help buttons to the app which display a brief explanation of the current section, to help a user in case they get stuck.

{\bf Step 4}: For our first cycle, we tested with three users. Each participant signed a consent form, and then sat down with a team member to complete the tasks. We gave each participant a quick briefing about our overall planned system use case. However we tried to give the testers as little technical advice as necessary so they could use the app as a real user would. {\bf Two of the users successfully completed all six of the tasks. One failed to complete the third task but completed the rest with guidance.} Some users got confused at task 2 and working out the need to move from the dashboard to the map to add residents.

{\bf Step 5}: Based on the results of this testing, the changes we will make to the app are as follows. Fully integrate the `help' dialogues into the app and perform testing to see if this improves usability and reduces failure rates at task 3. Add a `begin adding residents' button to the dashboard that takes them to the map and see if this makes task 2 easier to complete. Additionally, in testing, one user suggested adding more feedback from the robot to confirm that it was on its way. This indicates we should make the system status of the robot more visible to the user. We could do this by adding an avatar of the robot to show its movement over the map. Finally, as an additional test, we plan to perform A/B testing to compare different dashboard layouts to see which one shows relevant information more intuitively. 

\section{Budget}
\label{budget}
As with the previous demo, the bulk of our costs are associated with building, mounting, and integrating the lift. Tables \ref{tab:non-budget-cost}-\ref{tab:budget-cost-non-monetary} show spending to date including spending at previous demos. Equipment costs are based on values provided in the SDP wiki \cite{sdpcosts}.

\begin{table}[h]
\begin{center}
    \resizebox{\columnwidth}{!}{
  \begin{tabular}{lllll}
    {\bf Item} & {\bf Units} & {\bf Cost (\pounds\ per unit)} & {\bf Total cost (\pounds)} & {\bf Use} \\
    \hline
    Turtlebot Waffle & 1 & 1275.80 & 1275.80 & Robot \\
    Lego & 2.5kg & 15.00 & 37.50 & Lift \\
    EV3 large motor & 2 & 32.39 &  64.78 & Lift \\
    EV3 touch sensor & 2 & 19.19 & 38.38 & Lift \\
    Arduino kit & 1 & 60.00 & 60.00 & Lift \\
    \hline \hline
               &       & Overall cost (\pounds) & 1476.46
  \end{tabular}}
\caption{Non-budgeted monetary costs at demo \demoNumber. Note that we have chosen to stop using the EV3 and instead use the Arduino kit.}
\label{tab:non-budget-cost}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{lllll}
    {\bf Item} & {\bf Total cost (\pounds)} & {\bf Use} \\
    \hline
    Turtlebot supports  & 8.00 & Lift \\
    MDF support (12mm x 270mm x 400mm) & 1.00  & Lift \\ 
    Lift support rods & 5.00 & Lift \\
    Pegboard ($0.62 \text{m}^2$ at \pounds 12 per $2.88 \text{m}^2$)& 2.59 & Arena \\
    Misc (wires, screws, angle brackets) & 10.00 & Lift, arena \\
    MDF support (6 x 350  x 230mm) & 0.30 & Lift \\
    MDF support (9 x 70 x 230mm, 9 x 10 x 250mm (2x)) & 0.10 & Lift \\
    Engraved tray & 5.80 & Lift \\
    Weight sensors (2x) & 19.60 & Lift \\
    \hline
    \hline
     Budget spent (\pounds) & 52.39 \\
     Budget remaining (\pounds) & 147.61
  \end{tabular}}
\caption{Budgeted monetary costs at demo \demoNumber.}
\label{tab:budget-cost-monetary}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{lll}
    {\bf Purpose} & {\bf Hours spent} & {\bf Use} \\
    \hline
    Manufacturing lift support rods & 1 & Lift \\
    Manufacturing lift base (MDF) & 0.5 & Lift \\
    Drilling holes in lift base & 0.25 & Lift \\
    Engraving tray & 1 & Lift \\
    Attaching lift to base & 1 & Lift \\
    Cutting MDF to mount lift to base & 1 & Lift \\
    \hline
    \hline
    Overall technician hours spent & 4.75 & \\
    Total technician hours remaining & 2.25
  \end{tabular}}
\caption{Budgeted technician time at demo \demoNumber. Note that hours remaining includes subtracting any hours lost due to not being used in previous weeks.}
\label{tab:budget-cost-non-monetary}
\end{center}
\end{table}


% Clearpage also moves floats
\clearpage
\section{Appendix}
\subsection{Planned goals for demo 4}
\label{goals}
Below are our initially planned goals for demo 4 which we will not be able to complete:
\begin{itemize}
  \item Stop the robot from moving if the lift is extended, for safety reasons.
  \item Stop the lift from moving if it is overloaded (defined as loaded with a weight above 1.5kg).
  \item Test and choose the methodology for interpreting weight sensor reading values. This would involve first understanding how the voltages output map to the weights of objects placed on the sensors. Then we would test different orientations of the sensors under the tray, and decide how to combine the two sensor outputs, eg. by arithmetic or harmonic mean. 
  \item Implement checking of the battery charge on the lift, allowing for notification of both lift and robot battery status.
  \item Finalize and test connections between all components. 
\end{itemize}
\subsection{Software and hardware testing}
\label{testing}
We had planned to complete testing of the robot and lift to ensure it met the use case needs. We have not been able to complete these tests as planned. Below are the three tests we intended to do:

\begin{itemize}
\item To ensure the robot can consistently reach the target location for a delivery and return back to base, we would run the robot 10 times and measure how far it stopped from the goal. We defined the upper accuracy threshold as being 20cm radius away from the intended goal: this is still within reasonable reaching distance for a person collecting a delivery. If our testing found that the robot was not able to consistently stop within 20cm of the goal, ie. achieve this 9 out of 10 times, we planned to undertake further work to investigate and fix the source of this issue. 
\item We would also time how long each delivery took to ensure the robot can deliver food and water in a given amount of time (this is especially relevant if the food is hot). This would allow us to communicate to the caregiver a confidence interval for how long a delivery might take, as well as possibly send a notification to the app if the delivery were taking significantly longer than expected based on these tests.
\item The purpose of the weight sensors is to reliably be able to detect when objects have been placed onto and removed from the tray. We intended to perform tests where we would:
  \begin{itemize}
    \item Measure the weight with only the tray on top as the `empty' state of the lift.
    \item Place a cup, and then a plate, on the lift, measuring the changes in weight to mark the lift as containing a delivery. 
    \item Remove the cup, and then the plate, from the lift, measuring changes in weight to mark the delivery as completed. 
  \end{itemize}
  Based on a test run, we would program the lift control in the Turtlebot to be able to recognize when one or both objects were placed onto or removed from the tray. We would then perform 5 tests of these parameters by ensuring that the Turtlebot could reliably (5/5 times) recognize when both objects were placed on and taken off, or one at a time. 
\end{itemize}

\subsection{Details of robot $\leftrightarrow$ lift connection}
\label{connection}
The serial connection between the Raspberry Pi and the Arduino tends to have a variable response time and can sometimes break, not sending back any data.

As the Ardiuno is expected to always respond to messages from the Pi, we can check if it works by sending the `stop' command (a byte filled with zeroes) and waiting for a response. Usually it comes back within a fraction of a second, but sometimes it can lag, so we wait for up to one second. If no reply comes back, a reconnect function is executed, which repeatedly sends empty bytes every 50ms and checks if the input buffer fills up. When it detects a response, it waits an additional second and then clears the buffer. This way it's very unlikely the buffer fills up with late responses, delaying the connection. After a response is detected, most often it means the connection is working well again.

\begin{figure*}
  \begin{center}
    \includegraphics[width=1.8\columnwidth]{figs/connectivity.pdf}
  \end{center}
  \caption{The connections between each part of the system, showing what messages are sent during the use case.}
  \label{fig:connect-larger}
\end{figure*}

\begin{figure}
  \begin{center}
    \includegraphics[width=\columnwidth]{figs/weight_sensor.jpg}
    \caption{The top of the lift, showing the manufactured tray with the Tadashi logo and weight sensor underneath.}
  \label{fig:sensor}
  \end{center}
\end{figure}

\begin{figure}
  \begin{center}
    \includegraphics[width=\columnwidth]{figs/lift_detail.jpg}
    \caption{Inside view of lift mechanics. Note that the motors and sensors are now controlled by an Arduino to better allow for communication with the robot. }
  \label{fig:arduino}
  \end{center}
\end{figure}


\begin{table}[h]
\vskip 3mm
\begin{center}
\begin{tabular}{lcccc}
\hline
\abovespace\belowspace
Direction & x & y & z & w \\
\hline
  Forward & 0 & 0 & 0 & 1\\
  Backward & 0 & 0 & 1 & 0 \\
  Right & 0 & 0 & -0.7071 & 0.7071 \\
  Left & 0 & 0 & 0.7071 & 0.7071 
\end{tabular}
\caption{Quaternion movement inputs for each direction.}
\label{tab:quaternions}
\end{center}
\vskip -3mm
\end{table}
\begin{table}[h]
\vskip 3mm
\begin{center}
\begin{tabular}{lcc}
\hline
\abovespace\belowspace
Parameters & Original value & Our value \\
\hline
  max\_vel\_x & 0.26 & 0.1 \\
  min\_vel\_x & -0.26 & -0.1 \\
  max\_trans\_vel & 0.26 & 0.1 \\
  min\_trans\_vel & 0.13 & 0.07 \\
  max\_rot\_vel & 1.82 & 1.3 \\
  xy\_goal\_tolerance & 0.05 & 0.175 \\
  path\_distance\_bias & 32.0 & 65.0 \\
  goal\_distance\_bias & 20.0 & 40.0 \\
  occdist\_scale & 0.02 & 0.01
\end{tabular}
\caption{Our parameter alterations. [min/max]\_trans\_vel is the speed of the robot when moving in a straight line. path\_distance\_bias determines how closely the robot need follow the path it works out. goal\_distance\_bias smoothes the trajectory of the path and makes it more efficient. Finally, occdist\_scale determines how `afraid' the robot is of obstacles.}
\label{tab:params}
\end{center}
\vskip -3mm
\end{table}

\begin{tabular}{cc}
  \begin{minipage}{0.5\linewidth}
    \begin{table}[H]
      \centering
    \begin{tabular}{|l|}
      \hline
      \abovespace\belowspace
      DeliveryHistory \\
      \hline
      deliveryID \\
      time \\
      {\bf location} \\
      category \\
      weightBefore\\
      weightAfter\\
      {\it userID}\\
      deliverySuccessful \\
      \hline
    \end{tabular}
    
    \caption{DeliveryHistory table from Firebase.}
    \label{tab:delivery-history}
    \end{table}
  \end{minipage}
  \begin{minipage}{0.5\linewidth}
    \begin{table}[H]
      \centering
    \begin{tabular}{|l|}
      \hline
      \abovespace\belowspace
      Residents \\
      \hline
      {\it carer} \\
      firstName \\
      lastName \\
      {\bf location} \\
      priority \\
      \hline
    \end{tabular}
   
    \caption{Residents table from Firebase.}
    \label{tab:residents}
    \end{table}
  \end{minipage}
\end{tabular}

\clearpage
\bibliography{demo1-refs}


\end{document} 

