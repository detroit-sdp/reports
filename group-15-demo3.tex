%% Template for SDP report, adapted from mlp_cw2_template, 2018. 

%% Based on  LaTeX template for ICML 2017 - example_paper.tex at 
%%  https://2017.icml.cc/Conferences/2017/StyleAuthorInstructions

\documentclass{article}
\input{mlp2018_includes}

%% You probably do not need to change anything above this comment

%% REPLACE the details in the following commands with your details
\setGroupNumber{15}
\setGroupName{Detroit}
\setProductName{Tadashi}
\setDemoNumber{3}
\setLogoFileName{figs/logo-small.png}

\begin{document} 

\makeSDPTitle{Demo}

% Previous MLP Style Title Layout working. 
% \twocolumn[
    % \mlptitle{\productName: SDP Demo \demoNumber}
    % \centerline{Group \groupNumber: \groupName}
% ]

\begin{abstract}
  Tadashi is an assistive robot for delivering food and water to residents in supported living and care home environments.
  In this demo, we demonstrate significant progress towards a minimum viable product (MVP). We integrate components of our system together, demonstrating a full use-case: the caregiver placing a delivery on the tray and scheduling the robot to visit a room; the robot navigating to the room; the lift extending on arrival and detecting that the resident has picked up the delivery using integrated weight sensors; the lift retracting once the delivery has been made, and the robot sending a message to the app to indicate this; and the robot returning to its starting point. We also discuss usability testing we have performed on our app to ensure it is usable by non-technical caregivers, and discuss future improvements to the app based on this. 
\end{abstract} 

\section{Project plan update} 
\begin{itemize}
\item Begin testing app with non-technical users to gain insights on accessibility and ease of use: {\bf achieved}.
\item Make changes to app justified against results of testing: {\bf partially achieved}.
\item Complete user interviews with caregivers to assess demand for project features and implement new features based on caregiver requests: {\bf not achieved}.
\item Physically integrate lift mechanism into robot body, and integrate lift control into robot control software: {\bf partially achieved}.
\item Design and manufacture a tray to place on top of the lift to hold items: {\bf achieved}.
\item Add sensor to lift to determine whether items have been removed: {\bf achieved}.
\item Refine robot problem-solving when stuck by tuning mapping sensitivity and obstacle avoidance logic: {\bf partially achieved}. 
\item Implement bi-directional communication between the app and robot: {\bf achieved}.
\end{itemize}

We were not able to complete user interviews due to delays in receiving ethical approval (due to strike action). We intend to complete these as soon as we receive the approval. We were able to fully mount the lift onto the Turtlebot and partially able to implement communication between the robot and the lift, but the last part of this was scheduled for Saturday and therefore not completed due to the team having to move to remote work. Likewise, we were able to tune the robot's movement parameters, but we were not able to fully test this because of the team moving to remote work. 

\begin{table}[]
  \begin{tabular}{l|l}
    Task & Members \\
    \hline
    Robot refinements & Ben, Wojtek \\
    App refinements & Ching Ling, Yuchen \\
    Project management & Michael \\
    User testing & Theo \\
    Product development & Rebecca \\
    Lift building and mounting & Luukas \\
    Lift-robot connection & Errikos, Luukas, Jakub \\
    App-robot connection & Ben, Yuchen \\
  \end{tabular}
  \caption{Task splits across the group up to demo \demoNumber. Core teams and points of contact remain the same as with demo 2, but tasks were done by combining expertise across teams. }
  \label{tab:group-split}
\end{table}

We began the sprint with teams working the same as for demo 2 in order to refine individual components: refining robot problem-solving logic and movement parameters, refining the app, and finalizing the design and physical mounting of the lift. We then began focusing on the connections between aspects of our project. To do this, ad-hoc teams were created based on the knowledge each person had of the system they worked on, as seen in table \ref{tab:group-split}. To ensure effective collaboration, these teams met and worked in person, doing pair-programming to ensure expertise could be effectively utilised and to reduce the need to spend time integrating or merging code. As with previous sprints, code was tracked using GitHub for version control, and group communication was done through Slack and once-weekly meetings.

Our total budget spending so far consists of:
\begin{itemize}
  \item \pounds 0 ({\bf TODO update}) on non-budgeted monetary costs, ie. items taken from the starting kit and therefore not deducted from total budget;
  \item \pounds 30.80 on budgeted monetary costs to improve the lift, leaving us with \pounds 147.61 in our monetary budget; 
  \item 3 hours of technician time to mount the lift, leaving us with 1.25 hours technician time remaining. 
\end{itemize}

Owing to the ongoing coronavirus situation, the entire team began working remotely from Saturday 14th March. This means we need to halt work on the robot and the lift, as we cannot access or run these remotely. Decisions are still ongoing as to how to continue work in this situation, so our goals may change as the situation develops. Currently, we aim to do the following for demo 4:
\begin{itemize}
  \item Complete user interviews, analyse results, and implement changes to our product to match user demand.
  \item Improve app based on usability testing, and perform another round of usability tests to assess if changes have made a difference to usability. 
  \item Write the user guide. 
  \item Explore other technical additions to the product to ensure our technical time is spent in a way that adds value to the product. 
\end{itemize}

\section{Technical details}
\subsection{Connectivity}
To aid the reader with understanding how the system fits together, figure \ref{fig:connect} shows the connections we have set up between each of the parts that make up our product. The appendix also contains figure \ref{fig:seq} which shows how each part is involved in the running of the use case.
\begin{figure}
  \begin{center}
    \includegraphics[width=\columnwidth]{figs/connectivity.pdf}
  \end{center}
  \caption{The connections between each aspect of our product, showing what messages are sent during the use-case.}
  \label{fig:connect}
\end{figure}
\subsection{Hardware}

\subsection{User interface}
To break down the task of managing the robot, we have finalized the four fragments that make up the application using best practices for app design \cite{design, ux}:
\begin{enumerate}
  \item {\bf Dashboard}: this provides system status information at a glance to the user, showing how many deliveries were sent to each resident.
  \item {\bf Map}: this shows a top-down view of the care home ward, with icons to add a patient to each room.
  \item {\bf Calendar}: this allows users to set a schedule for the robot to follow and deliver at specific times.
  \item {\bf Me}: this contains account information and allows signing out. 
\end{enumerate}

The main focus for this demo was on the calendar fragment, and the networking service. The calendar has been set up with a basic UI design - pre user testing. This simple design allows the user to select any date, and for the given date it displays the robots itinerary (past and future) for that date, in chronological order.

 The events are stored and kept track of in a database within our Firebase setup. The database layout is described in table~\ref{tab:delivery-history} and table~\ref{tab:residents}. Bold entries represent fields that are linked between the tables, and italic entries represent fields which are linked to Firebase's authentication feature for secure user data storage. The robot status is stored using Firebase's realtime database as it is a constantly updating piece of information. As a final note, carer is the user is currently logged in when they add the resident to the system.

The communication was uni-directional for the previous demo (app$\rightarrow$robot). The difficulty in achieving bidirectionality arose due to the fact that the app runs on an emulator which essentially has no access to the outer world. We overcame this using a complex port forwarding setup. The host machine receives the packets on a port and forwards them to another port on itself. This second port is setup through the emulation software to forward all traffic onto a port on on the emulator 'device'.

To facilitate this connection, the app now has a network service running in the background until the app closes. We want to have the service run at all times, but unfortunately the service is destroyed eventually due to newer Android versions being optimised for power saving. The service may well have to be moved to the foreground in the future in order to achieve this.
\subsection{Software}


\subsubsection{Fine-tuning movement}
While operating, the robot knows its own position with respect to its starting point and the state of the map, with its starting point being the origin on the map. We set the starting position to be the base as marked on the arena floor. 

The navigation stack operates using vectors. When calculating the path from one point to another, the goal must be given as a pair of distances on the x and y axes and a rotation. The problem is that you are not always moving from the same base because the robot's view of its position may drift. In order to correct this, we decided to have our robot take in the coordinates of the goal and calculate the vector from its current position.

The robot views itself as always facing forward on the x axis: while you can specify a rotational move using a quaternion (x,y,z,w), the robot will always think of its own rotation as being (0,0,0,1). This means that in the view of the software, when turning, the axes rotate --- not the robot. To reduce problems this may cause we decided to restrict the robot to a four-directional goal system - forwards, backwards, right, and left with each having its own quaternion move (Table~\ref{tab:quaternions}).

When receiving a GOTO command from the app, we receive the room number. We use a dictionary to associate a room number with the coordinates of the room, and the targeted rotation at this goal (L, B, F, or R).

Based on observation, we believe that using the coordinates-vector system is more accurate over time than using distances. We were not able to test this before the team moved to remote working. 

In mounting the lift onto the Turtlebot, we increased the length of its footprint from 28.1cm to 40.0cm. We were concerned that this would cause the Turtlebot to drive into obstacles. We altered the <box\_size> parameter within the <collision> tag in the description of itself the robot provides to the navigation stack to reflect the change in size. The effect of this is difficult to test as we have set the robot to be very conserative in avoiding obstacles. 

We fine-tuned a number of parameters for the robot, described in table~\ref{tab:params}. [min/max]\_trans\_vel is the speed of the robot when moving in a straight line. path\_distance\_bias determines how closely the robot need follow the path it works out. goal\_distance\_bias smoothes the trajectory of the path and makes it more efficient. Finally, occdist\_scale determines how `afraid' the robot is of obstacles. 

\subsubsection{Communication with lift}
We had to establish a connection between the Turtlebot and the Arduino controlling the lift. We reviewed multiple options (Bluetooth, WiFi), but decided that the fastest and most reliable method would be to use a serial connection between USB ports on each board.

The code to extend and retract the lift was already on the Arduino, so it was a case of writing a Python script that could read/write bytes of data over the cable. The Raspberry Pi sends a single byte to the Arduino with possible values from 0-3 indicating stop, extend lift, and retract lift respectively. The Arduino returns the status of the lift as well as the current readings from the two weight sensors.

The connection was initially unreliable due to synchronization issues. After they were resolved we were able to reliably communicate with the lift.

\subsubsection{Communication with app}
To communicate the state of the robot to the app, the robot stores the following information internally:
\begin{itemize}
\item {\bf Low battery}: set if the battery level gets below 15\%. This state requires the caregiver to charge the robot. 
\item {\bf At base and not busy}. 
\item {\bf Moving}.
\item {\bf Assistance required}: set if the robot cannot find a path to the goal. This state requires rescue from the caregiver. 
\item {\bf Arrived at goal}.
\end{itemize}

Most of the work in terms of getting the bidirectional connectivity established with the app was done on the app side. The robot returns a packet to the app whenever the state changes. The packet simply contains one of the statuses listed above.

\subsection{Business development}

\section{Evaluation}
We performed usability testing to ensure the app was usable by non-technical caregivers. We decided to perform our testing in an iterative manner, performing three cycles of testing with app modifications during each cycle. Following discussions with Chris during his office hour, a cycle consists of:
\begin{enumerate}
  \item Prepare a testing task for the user to complete
  \item Self-evaluate our app against the task to check for clear problems
  \item Minor modifications to the task or app based on self-evaluation
  \item Conduct user testing
  \item Major app modifications based on testing
\end{enumerate}

For demo \demoNumber\ we performed one cycle of testing:

{\bf Step 1}: we set 6 steps for the user to follow, each relevant to one of the 10 usability principles \cite{heuristics}:
\begin{enumerate}
  \item Create an account and sign in. \\{\it Standardisation: since most users already have experience with sign-up screens, we used a default template.}
  \item Add 3 new residents to the rooms of the map. \\{\it Matching between the system and the real world: since the map represents a real care home floor, we want the user to intuitively recognize the layout, so the map is in the layout of the carehome.}
  \item Send Tadashi to deliver to a resident. \\{\it User control: we want the user to feel in control of the robot, so we provide feedback and undo options.}
  \item Set a delivery for a later date in the calendar. \\{\it Standardisation: the look of the scheduling system mimics Outlook, which users will be familiar with.}
  \item Report back information contained in the dashboard. \\{\it Visibility of system status: the dashboard is the most updated feature and contains key information, so it needs to display information relevant to the user in an intuitive manner.}
  \item Sign out. \\{\it Minimalism: we keep the settings area clear so users aren't confused on where to sign out.}
\end{enumerate}

{\bf Step 2}: During the self evaluation stage we completed a cognitive walkthrough of the app, putting us in the mind of a new user and completing our set tasks. The main problem found here was a general lack of direction and advice. Since the user starts at the dashboard, it wasn't immediately obvious that they should then use the map section to start adding residents.

{\bf Step 3}: To quickly aid this problem before testing, we decided to add help buttons to the app which display a brief explanation of the current section, to help guide a user in case they get stuck.

{\bf Step 4}: For our first cycle, we tested with three users. Each participant signed a consent form, and then sat down with a team member to complete the tasks. We gave each participant a quick briefing about our overall planned system use case. However we tried to give the testers as little technical advice as necessary so they could use the app as a real user would. {\bf Two of the testers successfully completed all the tasks. One failed to complete the third task but completed the rest with guidance.}

{\bf Step 5}: In testing, one user suggested adding more feedback from the robot to confirm that it was on its way. This point indicates that we should make the system status of the robot more visible to the user, however without over-sharing non relevant information. One future implementation could be adding an avatar of the robot to show its movement over the map.

\section{Budget}
As with the previous demo, the bulk of our costs are associated with building, mounting, and integrating the lift. Tables \ref{tab:non-budget-cost}-\ref{tab:budget-cost-non-monetary} show spending to date including spending at previous demos. Equipment costs are based on values provided in the SDP wiki \cite{sdpcosts}.

\begin{table}[h]
\begin{center}
    \resizebox{\columnwidth}{!}{
  \begin{tabular}{lllll}
    {\bf Item} & {\bf Units} & {\bf Cost (\pounds\ per unit)} & {\bf Total cost (\pounds)} & {\bf Use} \\
    \hline
    Turtlebot Waffle & 1 & 1275.80 & 1275.80 & Robot \\
    Lego & 2.5kg & 15.00 & 37.50 & Lift \\
    Arduino kit & 1 & 60.00 & 60.00 & Lift \\
    \hline \hline
               &       & Overall cost (\pounds) & 1373.3
  \end{tabular}}
\caption{Non-budgeted monetary costs at demo \demoNumber. Note that we have chosen to stop using the EV3 and instead use the Arduino kit.}
\label{tab:non-budget-cost}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{lllll}
    {\bf Item} & {\bf Total cost (\pounds)} & {\bf Use} \\
    \hline
    Turtlebot supports  & 8.00 & Lift \\
    MDF support (12mm x 270mm x 400mm) & 1.00  & Lift \\ 
    Lift support rods & 5.00 & Lift \\
    Pegboard ($0.62 \text{m}^2$ at \pounds 12 per $2.88 \text{m}^2$)& 2.59 & Arena \\
    Misc (wires, screws, angle brackets) & 10.00 & Lift, arena \\
    MDF support (6 x 350  x 230mm) & 0.30 & Lift \\
    MDF support (9 x 70 x 230mm, 9 x 10 x 250mm (2x)) & 0.10 & Lift \\
    Engraved tray & 5.80 & Lift \\
    Weight sensors (2x) & 19.60 & Lift \\
    \hline
    \hline
     Budget spent (\pounds) & 52.39 \\
     Budget remaining (\pounds) & 147.61
  \end{tabular}}
\caption{Budgeted monetary costs at demo \demoNumber.}
\label{tab:budget-cost-monetary}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{lll}
    {\bf Purpose} & {\bf Hours spent} & {\bf Use} \\
    \hline
    Manufacturing lift support rods & 1 & Lift \\
    Manufacturing lift base (MDF) & 0.5 & Lift \\
    Drilling holes in lift base & 0.25 & Lift \\
    Engraving tray & 1 & Lift \\
    Attaching lift to base & 1 & Lift \\
    Cutting MDF to mount lift to base & 1 & Lift \\
    \hline
    \hline
    Overall technician hours spent & 4.75 & \\
    Total technician hours remaining & 1.25
  \end{tabular}}
\caption{Budgeted technician time at demo \demoNumber. Note that hours remaining includes subtracting any hours lost due to not being used in previous weeks.}
\label{tab:budget-cost-non-monetary}
\end{center}
\end{table}


% Clearpage also moves floats
\clearpage
\section{Appendix}
\begin{figure}
  \begin{center}
    \includegraphics[width=\columnwidth]{figs/sequence.png}
  \end{center}
  \caption{A simplified view of the steps of our use case and how each part of the product is involved in the use case. Note that for simplicity, `Tadashi' represents both the Turtlebot and the ROS master.}
  \label{fig:seq}
\end{figure}
\begin{figure}
  \begin{center}
    \includegraphics[width=\columnwidth]{figs/weight_sensor.jpg}
    \caption{The top of the lift, showing the manufactured tray with the Tadashi logo and weight sensor underneath.}
  \label{fig:sensor}
  \end{center}
\end{figure}

\begin{figure}
  \begin{center}
    \includegraphics[width=\columnwidth]{figs/lift_view.jpg}
    \caption{Side view of the lift mounted to the Turtlebot. Points to note include the metal brackets used to fix the lift in place; the removal of the EV3 brick and addition of the Arduino kit and batteries; and the tray placed on top.}
  \label{fig:lift}
  \end{center}
\end{figure}

\subsection{Software and hardware testing}
We had planned to complete testing of the robot and lift to ensure it met the use-case needs. Unfortunately due to COVID-19 we were not able to complete these tests as planned. Below are the three tests we intended to do:

\begin{itemize}
\item To ensure the robot can consistently reach the target location for a delivery and return back to base, we would run the robot 10 times and measure how far it stopped from the goal. We defined the upper accuracy threshold as being 20cm radius away from the intended goal: this is still within reasonable reaching distance for a person collecting a delivery. If our testing found that the robot was not able to consistently stop within 20cm of the goal, ie. achieve this 9/10 times, we planned to undertake further work to investigate and fix the source of this issue. 
\item We would also time how long each delivery took to ensure the robot can deliver food and water in a given amount of time (this is especially relevant if the food is hot). This would allow us to communicate to the caregiver a confidence interval for how long a delivery might take, as well as possibly send a notification to the app if the delivery were taking significantly longer than expected based on thse tests.
\item The purpose of the weight sensors is to reliably be able to detect when objects have been placed onto and removed from the tray. We intended to perform tests where we would:
  \begin{itemize}
    \item Measure the weight with only the tray on top as the `empty' state of the lift.
    \item Place a cup, and then a plate, on the lift, measuring the changes in weight to mark the lift as containing a delivery. 
    \item Remove the cup, and then the plate, from the lift, measuring changes in weight to mark the delivery as completed. 
  \end{itemize}
  Based on a test run, we would program the lift control in the Turtlebot to be able to recognize when one or both objects were placed onto or removed from the tray. We would then perform 5 tests of these parameters by ensuring that the Turtlebot could reliably (5/5 times) recognize when both objects were placed on and taken off, or one at a time. 
\end{itemize}

\begin{table}[h]
\vskip 3mm
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccc}
\hline
\abovespace\belowspace
Direction & x & y & z & w \\
\hline
  Forward & 0 & 0 & 0 & 1\\
  Backwards & 0 & 0 & 1 & 0 \\
  Right & 0 & 0 & -0.7071 & 0.7071 \\
  Left & 0 & 0 & 0.7071 & 0.7071 
\end{tabular}
\end{sc}
\end{small}
\caption{Quaternion movement inputs for each direction.}
\label{tab:quaternions}
\end{center}
\vskip -3mm
\end{table}
\begin{table}[h]
\vskip 3mm
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcc}
\hline
\abovespace\belowspace
Parameters & Original value & Our value \\
\hline
  max\_vel\_x & 0.26 & 0.1 \\
  min\_vel\_x & -0.26 & -0.1 \\
  max\_trans\_vel & 0.26 & 0.1 \\
  min\_trans\_vel & 0.13 & 0.07 \\
  max\_rot\_vel & 1.82 & 1.3 \\
  xy\_goal\_tolerance & 0.05 & 0.175 \\
  path\_distance\_bias & 32.0 & 65.0 \\
  goal\_distance\_bias & 20.0 & 40.0 \\
  occdist\_scale & 0.02 & 0.01
\end{tabular}
\end{sc}
\end{small}
\caption{Our parameter alterations.}
\label{tab:params}
\end{center}
\vskip -3mm
\end{table}

\begin{table}[h]
\vskip 3mm
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{l}
\hline
\abovespace\belowspace
DeliveryHistory \\
\hline
  deliveryID \\
  time \\
  {\bf location} \\
  category \\
  weightBefore\\
  weightAfter\\
  {\it userID}\\
  deliverySuccessful
\end{tabular}
\end{sc}
\end{small}
\caption{DeliveryHistory table from Firebase.}
\label{tab:delivery-history}
\end{center}
\vskip -3mm
\end{table}

\begin{table}[h]
\vskip 3mm
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{l}
\hline
\abovespace\belowspace
Residents \\
\hline
  {\it carer} \\
  firstName \\
  lastName \\
  {\bf location} \\
  priority
\end{tabular}
\end{sc}
\end{small}
\caption{Residents table from Firebase.}
\label{tab:residents}
\end{center}
\vskip -3mm
\end{table}

\bibliography{demo1-refs}


\end{document} 

